{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooked-symphony",
   "metadata": {},
   "source": [
    "# Evaluation of the Different Approaches to AEP Detection on the Promise dataset (Section 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "willing-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Syntactic_Classifiers\n",
    "import ILLOD\n",
    "import Abbreviation_and_NC_Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-natural",
   "metadata": {},
   "source": [
    "## Reading the content of the PROMISE requirements. 30 abbreviations have been inserted in the texts. We want try to identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cutting-leeds",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "requirements_data = pd.read_csv('promise_constructed.CSV', names=['text', 'set_id'], sep=';', encoding='utf8')\n",
    "# print(requirements_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "miniature-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the data with the aim of storing it in a dictionary\n",
    "data_dict = {}\n",
    "for id_ in set(requirements_data[\"set_id\"]):\n",
    "    sublist = requirements_data[requirements_data[\"set_id\"] == id_]\n",
    "    data_dict[id_] = [req for req in sublist[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-surrey",
   "metadata": {},
   "source": [
    "## The following function performs a set transformation. It partitions objects of the set  ùëá  to the sets  ùëÇùëá  and  ùëá‚àñùëÇùëá according to steps (4) and (6) from section (6.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incident-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sets_for_term_types(set_of_abbreviations, set_of_terms):\n",
    "    \n",
    "    #compliant wit section 5.2: terms_that_contain_abbreviations = T \\ OT\n",
    "    terms_that_contain_abbreviations = set()\n",
    "    \n",
    "    for term in set_of_terms:\n",
    "        for abb in set_of_abbreviations:\n",
    "            if abb in term.split():\n",
    "                terms_that_contain_abbreviations.add(term)\n",
    "    \n",
    "    ordinary_terms = set_of_terms - terms_that_contain_abbreviations\n",
    "    \n",
    "    return ordinary_terms, terms_that_contain_abbreviations              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-creek",
   "metadata": {},
   "source": [
    "## Here we generate AEP Candidates and AEP groups with the different approches/ aep_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "special-apparatus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_aep_candidates_and_groups(aep_classifier):\n",
    "    counter = 0\n",
    "    overall_aep_candidates = []\n",
    "    AEP_candidate_clusters ={}\n",
    "    for id_ in data_dict.keys():\n",
    "\n",
    "        ######### Step(1) + Step(3): Extract set of Abbreviations A and set of terms T############\n",
    "\n",
    "        terms = set()\n",
    "        abbv_set = set()\n",
    "        # print(\"TUPLES FROM ReqSet: \" + str(id_))\n",
    "        for req in data_dict[id_]:\n",
    "            terms = terms.union(Abbreviation_and_NC_Extraction.nc_detect(req))\n",
    "            abbv_set = abbv_set.union(Abbreviation_and_NC_Extraction.abbv_detect(req))\n",
    "\n",
    "        ############ step(2): Reduce extracted abbreviations set A through cmparision with #######\n",
    "        ############ project resources so that only undefined abbreviations stay in A ############\n",
    "\n",
    "\n",
    "\n",
    "        ############################ step(4): determine the sets A, OT and T\\OT ##################\n",
    "        ordinary_terms, terms_that_contain_abbs = determine_sets_for_term_types(abbv_set, terms)\n",
    "\n",
    "\n",
    "        # For every a‚àà A generate an AEP group G^{a} of possible expansions t ‚àà OT via ILLOD.####\n",
    "        ###################################### step(5): ##########################################\n",
    "        abbreviations_with_matching_candidates = set()\n",
    "        for abv in abbv_set:\n",
    "            for term in ordinary_terms:\n",
    "                if aep_classifier(abv, term):\n",
    "                    overall_aep_candidates.append((abv, term.lower()))\n",
    "                    counter += 1\n",
    "                    abbreviations_with_matching_candidates.add(abv)\n",
    "                    #print(str(counter)+ \") (\" + abv + \", \" + term + \")\")\n",
    "                    if id_ in AEP_candidate_clusters.keys():\n",
    "                        if abv in AEP_candidate_clusters[id_]:\n",
    "                            expansion_candidates_list = AEP_candidate_clusters[id_][abv]\n",
    "                            expansion_candidates_list.append(term)\n",
    "                            AEP_candidate_clusters[id_][abv] = expansion_candidates_list\n",
    "                        else:\n",
    "                            AEP_candidate_clusters[id_][abv] = [term]\n",
    "                    else:\n",
    "                        AEP_candidate_clusters[id_] = {}\n",
    "\n",
    "        # For every a‚àà A extend its G^{a} with terms t‚àà T\\OT, if t contains a.####################\n",
    "        ######################################### step(6): #######################################\n",
    "        for abv in abbreviations_with_matching_candidates:\n",
    "            for term in terms_that_contain_abbs:\n",
    "                if abv in term.split() and abv != term:\n",
    "                    if id_ in AEP_candidate_clusters.keys():\n",
    "                        if abv in AEP_candidate_clusters[id_]:\n",
    "                            expansion_candidates_list = AEP_candidate_clusters[id_][abv]\n",
    "                            expansion_candidates_list.append(term)\n",
    "                            AEP_candidate_clusters[id_][abv] = expansion_candidates_list\n",
    "                        else:\n",
    "                            AEP_candidate_clusters[id_][abv] = [term]\n",
    "                    else:\n",
    "                        AEP_candidate_clusters[id_] = {}\n",
    "        #print(\"#####################################################\")\n",
    "    print(\"number of aep candidates: \" + str(counter))\n",
    "\n",
    "    cluster_counter = 0\n",
    "    for id_ in AEP_candidate_clusters.keys():\n",
    "        # print(\"CLUSTERS FROM ReqSet: \" + str(id_) + \":\")\n",
    "        for key in AEP_candidate_clusters[id_]:\n",
    "            cluster_counter += 1\n",
    "            # print(str(cluster_counter) + \") \" + \"\\\"\" + str(key)+ \"\\\"\" + \" : \" + str(AEP_candidate_clusters[id_][key]))\n",
    "        # print(\"#####################################################\")\n",
    "    print(\"number of aep grous: \" + str(cluster_counter))\n",
    "    return overall_aep_candidates\n",
    "\n",
    "def evaluate_aep_detection_approach(aep_classifier):\n",
    "    tuple_collection_for_evaluation = generate_aep_candidates_and_groups(aep_classifier)\n",
    "    inserted_abbreviations = pd.read_csv('insertedAbbreviations.txt', names=['expansion', 'abbreviation'], sep='\\t', encoding='utf8')\n",
    "    inserted_abbs = inserted_abbreviations[\"abbreviation\"].tolist()\n",
    "    inserted_exp = inserted_abbreviations[\"expansion\"].tolist()\n",
    "    inserted_abbreviations_as_tuples = [(inserted_abbs[i], inserted_exp[i]) for i in range(0, len(inserted_exp))]\n",
    "\n",
    "    def contains_exp(proper_tuple, tup):\n",
    "        cont = True\n",
    "        for t in proper_tuple[1].split():\n",
    "            exp_candidate_lower = tup[1].lower()\n",
    "            if t not in exp_candidate_lower.split():\n",
    "                cont = False\n",
    "        if cont:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    matches_for_final_eval = 0\n",
    "    resolved_abbs = set()\n",
    "    print(\"FOUND AEPs:\")\n",
    "    for tup in tuple_collection_for_evaluation:\n",
    "        for proper_tuple in inserted_abbreviations_as_tuples:\n",
    "            if tup == proper_tuple and contains_exp(proper_tuple, tup):\n",
    "                if tup[0] not in resolved_abbs:\n",
    "                    print(tup)\n",
    "                    resolved_abbs.add(tup[0])\n",
    "                    matches_for_final_eval += 1\n",
    "    print(matches_for_final_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-discipline",
   "metadata": {},
   "source": [
    "## Main Program to count the bumber of generated AEP candidates, AEP groups and to show corectly detected AEPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "emotional-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of aep candidates: 115\n",
      "number of aep grous: 49\n",
      "FOUND AEPs:\n",
      "('cT', 'current time')\n",
      "('RT', 'realtor')\n",
      "('SR', 'search result')\n",
      "('DS', 'disputes system')\n",
      "('NSM', 'nursing staff member')\n",
      "('DC', 'dispute case')\n",
      "('Csi', 'clinical site')\n",
      "('RF', 'repair facility')\n",
      "('rP', 'recycled part')\n",
      "('CE', 'collision estimate')\n",
      "('AR', 'audit report')\n",
      "('SP', 'search parameter')\n",
      "('CR', 'conference room')\n",
      "('sI', 'substitutionary ingredient')\n",
      "('PF', 'product formula')\n",
      "('IQA', 'inventory quantity adjustment')\n",
      "('Sys', 'system')\n",
      "('sMo', 'streaming movie')\n",
      "('CC', 'credit card')\n",
      "('LeSco', 'lead score')\n",
      "('WES', 'web service')\n",
      "('LeDA', 'lead data')\n",
      "('oP', 'offensive player')\n",
      "('dG', 'defensive grid')\n",
      "('STAT', 'status')\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ILLOD\n",
    "evaluate_aep_detection_approach(ILLOD.illod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "entitled-metallic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of aep candidates: 870\n",
      "number of aep grous: 70\n",
      "FOUND AEPs:\n",
      "('cT', 'current time')\n",
      "('RT', 'realtor')\n",
      "('SR', 'search result')\n",
      "('DS', 'disputes system')\n",
      "('NSM', 'nursing staff member')\n",
      "('DC', 'dispute case')\n",
      "('Csi', 'clinical site')\n",
      "('RF', 'repair facility')\n",
      "('rP', 'recycled part')\n",
      "('CE', 'collision estimate')\n",
      "('AR', 'audit report')\n",
      "('SP', 'search parameter')\n",
      "('CR', 'conference room')\n",
      "('sI', 'substitutionary ingredient')\n",
      "('PF', 'product formula')\n",
      "('IQA', 'inventory quantity adjustment')\n",
      "('sMo', 'streaming movie')\n",
      "('CC', 'credit card')\n",
      "('WES', 'web service')\n",
      "('oP', 'offensive player')\n",
      "('dG', 'defensive grid')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Levenshtein-Distance_Classifier\n",
    "evaluate_aep_detection_approach(Syntactic_Classifiers.ld_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "built-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of aep candidates: 251\n",
      "number of aep grous: 63\n",
      "FOUND AEPs:\n",
      "('cT', 'current time')\n",
      "('RT', 'realtor')\n",
      "('SR', 'search result')\n",
      "('DS', 'disputes system')\n",
      "('NSM', 'nursing staff member')\n",
      "('DC', 'dispute case')\n",
      "('Csi', 'clinical site')\n",
      "('RF', 'repair facility')\n",
      "('rP', 'recycled part')\n",
      "('CE', 'collision estimate')\n",
      "('AR', 'audit report')\n",
      "('SP', 'search parameter')\n",
      "('CR', 'conference room')\n",
      "('sI', 'substitutionary ingredient')\n",
      "('PF', 'product formula')\n",
      "('IQA', 'inventory quantity adjustment')\n",
      "('sMo', 'streaming movie')\n",
      "('CC', 'credit card')\n",
      "('LeSco', 'lead score')\n",
      "('LeDA', 'lead data')\n",
      "('oP', 'offensive player')\n",
      "('dG', 'defensive grid')\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Jaro-Winkler-Similarity_Classifier\n",
    "evaluate_aep_detection_approach(Syntactic_Classifiers.jws_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rational-catch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of aep candidates: 258\n",
      "number of aep grous: 65\n",
      "FOUND AEPs:\n",
      "('cT', 'current time')\n",
      "('SR', 'search result')\n",
      "('DS', 'disputes system')\n",
      "('NSM', 'nursing staff member')\n",
      "('DC', 'dispute case')\n",
      "('Csi', 'clinical site')\n",
      "('RF', 'repair facility')\n",
      "('rP', 'recycled part')\n",
      "('CE', 'collision estimate')\n",
      "('AR', 'audit report')\n",
      "('SP', 'search parameter')\n",
      "('CR', 'conference room')\n",
      "('sI', 'substitutionary ingredient')\n",
      "('PF', 'product formula')\n",
      "('IQA', 'inventory quantity adjustment')\n",
      "('sMo', 'streaming movie')\n",
      "('CC', 'credit card')\n",
      "('WES', 'web service')\n",
      "('oP', 'offensive player')\n",
      "('dG', 'defensive grid')\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Dice_Coefficient-Classiifer\n",
    "evaluate_aep_detection_approach(Syntactic_Classifiers.dc_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
