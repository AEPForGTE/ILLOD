{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooked-symphony",
   "metadata": {},
   "source": [
    "# Integration of ILLOD into the clustering of glossary term candidates (Section 6.2, Figure 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "willing-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Syntactic_Classifiers\n",
    "import ILLOD\n",
    "import Abbreviation_and_NC_Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-wagner",
   "metadata": {},
   "source": [
    "## Helper Functions for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "linear-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_dict (prediction_list, terms_list):\n",
    "    dict_for_mapping = {}\n",
    "    for i, cluster_id in enumerate(prediction_list):\n",
    "        if int(cluster_id) in dict_for_mapping:\n",
    "            tmp = dict_for_mapping[int(cluster_id)]\n",
    "            tmp.append(terms_list[i])\n",
    "            dict_for_mapping[int(cluster_id)] = tmp\n",
    "        else:\n",
    "            dict_for_mapping[int(cluster_id)] = [terms_list[i]]\n",
    "    return dict_for_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-natural",
   "metadata": {},
   "source": [
    "## Reading the content of the PROMISE requirements. 30 abbreviations have been inserted in the texts. We try to identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cutting-leeds",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "requirements_data = pd.read_csv('promise_constructed.CSV', names=['text', 'set_id'], sep=';', encoding='utf8')\n",
    "# print(requirements_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "miniature-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the data with the aim of storing it in a dictionary\n",
    "# Focus on requirements set number 5 (auto part finder system)\n",
    "data_dict = {}\n",
    "for id_ in set(requirements_data[\"set_id\"]):\n",
    "    sublist = requirements_data[requirements_data[\"set_id\"] == id_]\n",
    "    data_dict[id_] = [req for req in sublist[\"text\"]]\n",
    "test_reqs = data_dict[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-surrey",
   "metadata": {},
   "source": [
    "## The following function performs a set transformation. It partitions objects of the set  ùëá  to the sets  ùëÇùëá  and  ùëá‚àñùëÇùëá according to steps (4) and (6) from Section 6.2, Figure 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "incident-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sets_for_term_types(set_of_abbreviations, set_of_terms):\n",
    "    \n",
    "    #compliant wit section 5.2: terms_that_contain_abbreviations = T \\ OT\n",
    "    terms_that_contain_abbreviations = set()\n",
    "    \n",
    "    for term in set_of_terms:\n",
    "        for abb in set_of_abbreviations:\n",
    "            if abb in term.split():\n",
    "                terms_that_contain_abbreviations.add(term)\n",
    "    \n",
    "    ordinary_terms = terms - terms_that_contain_abbreviations\n",
    "    \n",
    "    return ordinary_terms, terms_that_contain_abbreviations              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-bulletin",
   "metadata": {},
   "source": [
    "## Generation of Clusters according to steps(1) till step(8) (Section 6.2, Figure 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "incident-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['environment', 'supervisor role', 'city', 'list', 'miles', 'audit', 'initial launch', 'Sarbanes - Oxley', 'invalid datum', '90 %', 'claim processing', 'street address', 'instruction', 'appearance', 'maintenance', 'adjuster', 'insurance companys claim datum', '98 %', '95 %', 'indivual line item', 'denial', 'other adjuster', 'feed', 'computer virus', 'access', '1 month', '80 %', 'category', 'insurance regulation', '85 %', 'product installation', 'application', 'approximately 1:00 am']\n",
      "############################################################\n",
      "6\n",
      "['estimator', 'estimate', '80 % of Collision Estimators', 'Collision Estimators', 'collision estimate', 'available recycled part and collision estimate', 'recycled part audit of collision estimate', 'productivity of Collision Estimators', 'collision estimator', 'only collision estimator', 'estimate assignment', 'adjuster and Collision Estimators', 'collision estimator role']\n",
      "############################################################\n",
      "4\n",
      "['high rating', 'rating', 'new rating', '98 % uptime', 'blank set of rating', 'attempt use']\n",
      "############################################################\n",
      "7\n",
      "['Choice part System', 'ChoiceParts system', 'system', '90 % of system']\n",
      "############################################################\n",
      "3\n",
      "['corporate support center', 'corporate color scheme', 'schedule outage', 'availability schedule', 'corporate online availability schedule', 'corporate Architecture guideline', 'establish corporate maintenance window', '98 % of schedule outage']\n",
      "############################################################\n",
      "10\n",
      "['1500 user', 'up to 1500 simultaneous user', 'corporate User Interface Guidelines', 'user', '10 000 concurrent user', 'User help', '85 % of user']\n",
      "############################################################\n",
      "11\n",
      "['vehicle location', 'supplied vehicle part and supplier', 'vehicle year', 'vehicle datum', 'vehicle vehicle location', 'damaged vehicle part information', 'supplied vehicle part']\n",
      "############################################################\n",
      "2\n",
      "['only valid datum', 'supplier', 'scale', 'only adjuster', '15 second', 'training', '10 second', 'service', 'upgrade', 'percentage', 'audit report', 'middleware technology team', '5 second', '2 year', 'radius', 'product', '8 second', 'save', 'state']\n",
      "############################################################\n",
      "0\n",
      "['exist hardware', 'Mozilla Firefox', 'estimatic law', 'internet explorer', 'later point', 'day', 'malicious attack', 'one insurance company', 'input criterion', 'adjuster role', 'productivity', 'two day', 'blank set']\n",
      "############################################################\n",
      "13\n",
      "['no long than 15 second', 'establish launch time frame', 'more than 2 %', 'more than 2 % of available online time', 'time', 'available online time']\n",
      "############################################################\n",
      "5\n",
      "['part', 'preferred part supplier', 'available recycled part', 'recycled part datum', 'select recycled part', 'percentage of available recycled part', 'feed of recycled part datum', 'recycled part', 'available part', 'available recycled part information', 'recycled part audit report', 'recycled part audits', 'available recycled part information and supplier', 'number of available recycled part', 'recycled part record', 'recycled part audit', 'available recycled part and supplier']\n",
      "############################################################\n",
      "9\n",
      "['average number', 'total number of recycled part', '95 % of adjuster', 'denial of service', 'appearance of product', '2 year of initial launch', 'list of preferred part supplier', 'average number of recycled part record', 'total score of audit', 'number', 'total score', 'maintenance of product', 'total number']\n",
      "############################################################\n",
      "8\n",
      "['1 and 30 mile', 'radius of 30 mile', '30 mile', 'rp and actual use', 'dirty and noisy condition', 'product installation and upgrade']\n",
      "############################################################\n",
      "14\n",
      "['zipcode']\n",
      "############################################################\n",
      "12\n",
      "['preferred repair facility rating', 'repair facility', 'list of repair facility', 'repair facility rating', 'preferred repair facility', 'current repair facility rating']\n",
      "############################################################\n",
      "15\n",
      "['search', 'search radius', 'original search result', 'search result', 'recycled part search result']\n",
      "############################################################\n",
      "RF\n",
      "['repair facility', 'prefer RF', 'RF']\n",
      "############################################################\n",
      "rP\n",
      "['recycled part', 'attempt use of rP', 'rp and actual use of rP', 'attempt use of rP and actual use', 'rP']\n",
      "############################################################\n",
      "AR\n",
      "['appearance', 'adjuster', 'audit report', 'available part', 'adjuster role', 'AR']\n",
      "############################################################\n",
      "CE\n",
      "['Collision Estimators', 'claim processing', 'collision estimate', 'collision estimator', 'category', 'CE']\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "######## Step(1) + Step(3): Extract set of Abbreviations A and set of terms T ############\n",
    "terms = set()\n",
    "abbv_set = set()\n",
    "for req in test_reqs:\n",
    "    terms = terms.union(Abbreviation_and_NC_Extraction.nc_detect(req))\n",
    "    abbv_set = abbv_set.union(Abbreviation_and_NC_Extraction.abbv_detect(req))\n",
    "\n",
    "\n",
    "########## placeholder for step(2): Reduce extracted abbreviations set A through #########\n",
    "#########  cmparision with project resources so that only undefined abbreviations stay in A\n",
    "\n",
    "\n",
    "###################### step(4): determine the sets A, OT and T\\OT ########################\n",
    "ordinary_terms, terms_that_contain_abbs = determine_sets_for_term_types(abbv_set, terms)\n",
    "\n",
    "\n",
    "\n",
    "# For every a‚àà A generate an AEP group G^{a} of possible expansions t ‚àà OT via ILLOD.####\n",
    "###################################### step(5): ##########################################\n",
    "AEP_candidate_clusters = {}\n",
    "abbreviations_with_matching_candidates = set()\n",
    "for abv in abbv_set:\n",
    "    for term in ordinary_terms:\n",
    "        if ILLOD.illod(abv, term):\n",
    "            abbreviations_with_matching_candidates.add(abv)\n",
    "            if abv in AEP_candidate_clusters:\n",
    "                expansion_candidates_list = AEP_candidate_clusters[abv]\n",
    "                expansion_candidates_list.append(term)\n",
    "                AEP_candidate_clusters[abv] = expansion_candidates_list\n",
    "            else:\n",
    "                AEP_candidate_clusters[abv] = [term]\n",
    "\n",
    "# For every a‚àà A extend its G^{a} with terms t‚àà T\\OT, if t contains a.####################\n",
    "######################################### step(6): #######################################\n",
    "for abv in abbreviations_with_matching_candidates:\n",
    "    for term in terms_that_contain_abbs:\n",
    "        if abv in term.split() and abv != term:\n",
    "            if abv in AEP_candidate_clusters:\n",
    "                expansion_candidates_list = AEP_candidate_clusters[abv]\n",
    "                expansion_candidates_list.append(term)\n",
    "                AEP_candidate_clusters[abv] = expansion_candidates_list\n",
    "            else:\n",
    "                AEP_candidate_clusters[abv] = [term]\n",
    "\n",
    "####################### step(7): generate clusters for terms from OT #####################\n",
    "tfidf = TfidfVectorizer()\n",
    "X = pd.DataFrame(tfidf.fit_transform(ordinary_terms).toarray(),\n",
    "                 index=list(ordinary_terms), columns=tfidf.get_feature_names())\n",
    "cluster_dict = {}\n",
    "gmm = GaussianMixture(n_components=16).fit(X)\n",
    "pred = gmm.predict(X)\n",
    "cluster_dict = create_cluster_dict(pred, list(ordinary_terms))\n",
    "\n",
    "\n",
    "\n",
    "## step(8): Add AEP groups as additional clusters to the clusters of the ordinary terms ##\n",
    "for key in  AEP_candidate_clusters:\n",
    "    tmp_list = AEP_candidate_clusters[key]\n",
    "    tmp_list.append(key)\n",
    "    cluster_dict[key] = tmp_list\n",
    "\n",
    "    \n",
    "################################# print on terminal ######################################\n",
    "for key in cluster_dict.keys():\n",
    "    print(str(key))\n",
    "    print(cluster_dict[key])\n",
    "    print(\"############################################################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
