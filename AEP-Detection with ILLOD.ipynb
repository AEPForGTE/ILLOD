{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviation-Expansion List\n",
    "Before we go into the details of the ILLOD tool, we first will give some insights into our evaluation data for AEP-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('abbr_db.CSV', names=['abbr', 'long_forms'], sep=';', encoding='utf8')\n",
    "abbreviations = list(data['abbr'].values)\n",
    "expansions = list(data['long_forms'].values)\n",
    "#for i, abb in enumerate(abbreviations):\n",
    "#    print(str(i) + \": \" + abb + \"| \" + expansions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Helper Functions\n",
    "These helper functions are needed in order to provide important methods for syntactic and semantic similarity measures and for ILLOD. We need a method to calculate the dice coefficient between two given strings since the jellyfish package doesnt provide this funcionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(a, b):\n",
    "    \"\"\"dice coefficient 2nt/(na + nb).\"\"\"\n",
    "    a_bigrams = set(a.lower())\n",
    "    b_bigrams = set(b.lower())\n",
    "    overlap = len(a_bigrams & b_bigrams)\n",
    "    return overlap * 2.0 / (len(a_bigrams) + len(b_bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to remove puntuation marks from  a given strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    s_lower = s.lower()\n",
    "    invalidcharacters = set(string.punctuation)\n",
    "    if any(char in invalidcharacters for char in s):\n",
    "        s_ = s_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "    else:\n",
    "        s_ = s_lower\n",
    "    return s_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to remove stop words from  a given term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_handling(term):\n",
    "    splitted_term = term.split()\n",
    "    stop_words = set([\"for\", \"and\", \"of\", \"in\", \"via\", \"be\"])\n",
    "    \n",
    "    # As first character matching is important, stop words are not removed when they are the first word\n",
    "    first_word = splitted_term[0]\n",
    "    if first_word in stop_words:\n",
    "        stop_words = stop_words - set([splitted_term[0]])\n",
    "                \n",
    "    for sw in stop_words:\n",
    "        while sw in splitted_term:\n",
    "            splitted_term.remove(sw)\n",
    "    sanitized_term = \" \".join([w for w in splitted_term]) \n",
    "        \n",
    "    return sanitized_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to calculate and return $(a^{c}, potAbb(t^{c}))$  for a given pair $(a,t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string_pair_and_reduce_expansion(abb, term):\n",
    "    abb_lower = abb.lower()\n",
    "    term_lower = term.lower()\n",
    "    sanitized_abbv = clean_string(abb_lower)\n",
    "    sanitized_term = clean_string(term_lower)   \n",
    "    sanitized_term_without_stopswords = stop_words_handling(sanitized_term)\n",
    "    initial_letters_of_tokens_of_sanitized_term_without_stopswords = ''.join([c[0] for c in sanitized_term_without_stopswords.split()])\n",
    "    return sanitized_abbv, initial_letters_of_tokens_of_sanitized_term_without_stopswords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers based on semantic similarity (FastText)\n",
    "## Algortihm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "from scipy import spatial\n",
    "# fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft = fasttext.load_model(\"cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_similarity(a, t, threshold):\n",
    "    \n",
    "    a_v = ft.get_word_vector(a)\n",
    "    t_v = ft.get_word_vector(t)\n",
    "    if 1 - spatial.distance.cosine(a_v, t_v) >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cosine Similarity on Fasttext Wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_sim(a, t):\n",
    "    \n",
    "    a_v = ft.get_word_vector(a)\n",
    "    t_v = ft.get_word_vector(t)\n",
    "    return 1 - spatial.distance.cosine(a_v, t_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers based on syntactic similarity (LD, JWS, DC, DC)\n",
    "## Algorithm 2 in different variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levensthein_distance_on_reduction_of_expansion(a, term, threshold):\n",
    "    a_, t_ = clean_string_pair_and_reduce_expansion(a, term)\n",
    "    if jellyfish.levenshtein_distance(a_, t_) <= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_winkler_similarity_on_reduction_of_expansion(a, term, threshold):\n",
    "    a_, t_ = clean_string_pair_and_reduce_expansion(a, term)\n",
    "    if jellyfish.jaro_winkler_similarity(a_, t_) >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient_on_reduction_of_expansion(a, term, threshold):\n",
    "    a_, t_ = clean_string_pair_and_reduce_expansion(a, term)\n",
    "    if dice_coefficient(a_, t_) >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicability: \n",
    "## Similarities for Table 1 (Section 4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_AEP_pairs = [\n",
    "    (\"LED monitor\", \"light-emitting diode\"),\n",
    "    (\"Int\", \"integer\"),\n",
    "    (\"PS/2\", \"Personal System/2\"),\n",
    "    (\"IANA\", \"Internet Assigned Numbers Authority\"),\n",
    "    (\"SMM\", \"System Management Mode\"),\n",
    "    (\"U/L\", \"upload\"),\n",
    "    (\"IAP\", \"Internet access provider\"),\n",
    "    (\"CLNS\", \"connectionless network service\"),\n",
    "    (\"MMC\", \"MultiMediaCard\"),\n",
    "    (\"I/O\", \"input/output\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (LED monitor, light-emitting diode)\n",
      "LD: 0.15000000000000002\n",
      "DLD: 0.15000000000000002\n",
      "JS: 0.4348484848484849\n",
      "JWS: 0.4348484848484849\n",
      "DC: 0.8181818181818182\n",
      "FT: 0.2985321581363678\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (Int, integer)\n",
      "LD: 0.2857142857142857\n",
      "DLD: 0.2857142857142857\n",
      "JS: 0.6507936507936508\n",
      "JWS: 0.6507936507936508\n",
      "DC: 0.6666666666666666\n",
      "FT: 0.20010310411453247\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (PS/2, Personal System/2)\n",
      "LD: 0.23529411764705888\n",
      "DLD: 0.23529411764705888\n",
      "JS: 0.4362745098039216\n",
      "JWS: 0.4362745098039216\n",
      "DC: 0.4444444444444444\n",
      "FT: 0.18993335962295532\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (IANA, Internet Assigned Numbers Authority)\n",
      "LD: 0.11428571428571432\n",
      "DLD: 0.11428571428571432\n",
      "JS: 0.611904761904762\n",
      "JWS: 0.611904761904762\n",
      "DC: 0.3157894736842105\n",
      "FT: 0.09341581165790558\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (SMM, System Management Mode)\n",
      "LD: 0.13636363636363635\n",
      "DLD: 0.13636363636363635\n",
      "JS: 0.5858585858585859\n",
      "JWS: 0.5858585858585859\n",
      "DC: 0.3076923076923077\n",
      "FT: 0.14236025512218475\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (U/L, upload)\n",
      "LD: 0.0\n",
      "DLD: 0.0\n",
      "JS: 0.0\n",
      "JWS: 0.0\n",
      "DC: 0.4444444444444444\n",
      "FT: -0.0247600469738245\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (IAP, Internet access provider)\n",
      "LD: 0.04166666666666663\n",
      "DLD: 0.04166666666666663\n",
      "JS: 0.4583333333333333\n",
      "JWS: 0.4583333333333333\n",
      "DC: 0.375\n",
      "FT: 0.06012619659304619\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (CLNS, connectionless network service)\n",
      "LD: 0.0\n",
      "DLD: 0.0\n",
      "JS: 0.0\n",
      "JWS: 0.0\n",
      "DC: 0.47058823529411764\n",
      "FT: 0.07574982196092606\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (MMC, MultiMediaCard)\n",
      "LD: 0.2142857142857143\n",
      "DLD: 0.2142857142857143\n",
      "JS: 0.6031746031746031\n",
      "JWS: 0.6031746031746031\n",
      "DC: 0.3333333333333333\n",
      "FT: 0.5328943729400635\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Similarities for (I/O, input/output)\n",
      "LD: 0.08333333333333337\n",
      "DLD: 0.08333333333333337\n",
      "JS: 0.47222222222222215\n",
      "JWS: 0.47222222222222215\n",
      "DC: 0.6\n",
      "FT: 0.1474282294511795\n"
     ]
    }
   ],
   "source": [
    "measures = [\"LD\", \"DLD\", \"JS\", \"JWS\", \"DC\", \"FT\"]\n",
    "for aep_tuple in random_AEP_pairs:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"Similarities for (\" + aep_tuple[0] + \", \" + aep_tuple[1] + \")\")\n",
    "    for j, measure in enumerate([jellyfish.levenshtein_distance, jellyfish.damerau_levenshtein_distance, jellyfish.jaro_similarity, jellyfish.jaro_winkler_similarity, dice_coefficient, fast_text_sim]):\n",
    "        if measure in [jellyfish.levenshtein_distance, jellyfish.damerau_levenshtein_distance]:\n",
    "            print(measures[j] +\": \" + str(1 - (measure(aep_tuple[0], aep_tuple[1])/max(len(aep_tuple[0]), len(aep_tuple[1])))))\n",
    "        else:\n",
    "            print(measures[j] +\": \" + str(measure(aep_tuple[0], aep_tuple[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to calculate values for Table 2 (Section 4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_similarity (abbreviation_list, terms_list):\n",
    "    similarity_measures = [jellyfish.levenshtein_distance, jellyfish.jaro_winkler_similarity, dice_coefficient]\n",
    "    result_list = []\n",
    "    for sim in similarity_measures:\n",
    "        tmp_sim = 0\n",
    "        for index, abb in enumerate(abbreviation_list):\n",
    "            term = terms_list[index]\n",
    "            if sim == jellyfish.levenshtein_distance:\n",
    "                tmp_sim = tmp_sim + (1 - (sim(abb, term)/max(len(abb), len(term))))\n",
    "            else:\n",
    "                tmp_sim = tmp_sim + sim(abb, term)\n",
    "        result_list.append(tmp_sim/len(abbreviation_list))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09244587264953216, 0.3104687280041735, 0.41868180511878067]\n"
     ]
    }
   ],
   "source": [
    "# Average distance on pairs (a,t) for the measures LD, JWS, DC:\n",
    "\n",
    "print(calculate_average_similarity(abbreviations, expansions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18251453867995351, 0.644198269507842, 0.42211256293446175]\n"
     ]
    }
   ],
   "source": [
    "# Average distance on pairs (a^{c},t^{c}) for the measures LD, JWS, DC:\n",
    "\n",
    "abbreviations_removed_sw = [stop_words_handling(abb) for abb in abbreviations]\n",
    "terms_removed_sw = [stop_words_handling(term) for term in expansions]\n",
    "abbreviations_cleaned = [clean_string(abb) for abb in abbreviations_removed_sw]\n",
    "terms_cleaned = [clean_string(term) for term in terms_removed_sw]\n",
    "\n",
    "\n",
    "print(calculate_average_similarity(abbreviations_cleaned, terms_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3613525520945073, 0.42489010048036335, 0.8611033252550622]\n"
     ]
    }
   ],
   "source": [
    "# Average distance on pairs (a,â) for the measures LD, JWS, DC:\n",
    "\n",
    "potential_abbreviations = [''.join([c[0] for c in term.split()]) for term in expansions]\n",
    "print(calculate_average_similarity(abbreviations, potential_abbreviations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7969252528477795, 0.9022384139498926, 0.8646839240764218]\n"
     ]
    }
   ],
   "source": [
    "# Average distance on pairs (a^{c},â^{c}) for the measures LD, JWS, DC:\n",
    "\n",
    "potential_abbreviations_of_cleaned_terms = [''.join([c[0] for c in term.split()]) for term in terms_cleaned]\n",
    "print(calculate_average_similarity(abbreviations_cleaned, potential_abbreviations_of_cleaned_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average length of abbreviations after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5498320268756998\n"
     ]
    }
   ],
   "source": [
    "# Average length after pre-processing\n",
    "tmp_len = 0\n",
    "for abb in abbreviations_cleaned:\n",
    "    tmp_len = tmp_len + len(abb)\n",
    "print(tmp_len/len(abbreviations_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cardinality of S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710125\n"
     ]
    }
   ],
   "source": [
    "# construction and cardinality of S:\n",
    "S = set()\n",
    "for i, abb in enumerate(abbreviations):\n",
    "    for j, exp in enumerate (expansions):\n",
    "        if abb != abbreviations[j]:\n",
    "            S.add((abb, exp))\n",
    "print(len(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILLOD with its Methods (Section 4.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_initial_letters(a, t):\n",
    "    initial_letters_of_tokens_of_t = ''.join([c[0] for c in t.split()])\n",
    "    if initial_letters_of_tokens_of_t == a or initial_letters_of_tokens_of_t.upper() == a:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length_consistency(a, t):\n",
    "    length_consistency = False\n",
    "    if len(t.split()) <= len(a):\n",
    "        length_consistency = True\n",
    "    return length_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order(a, t):\n",
    "    abbv_reversed = a.lower()[::-1]\n",
    "    term_reversed = t.lower()[::-1]\n",
    "    len_of_term = len(t)\n",
    "    \n",
    "    pos_memory = 0\n",
    "    pos_memory_list = []\n",
    "    order_matching_string_rev = \"\"\n",
    "    \n",
    "    for j, char_from_abbv in enumerate(abbv_reversed):\n",
    "        if j == len(abbv_reversed) - 1 and len(pos_memory_list) > 0 and pos_memory == len(term_reversed):\n",
    "            break\n",
    "        else:\n",
    "            for i, char_from_term in enumerate(term_reversed[pos_memory:]):\n",
    "                if char_from_abbv == char_from_term:\n",
    "                    order_matching_string_rev = order_matching_string_rev + char_from_abbv\n",
    "                    pos_memory = pos_memory + i + 1\n",
    "                    pos_memory_list.append(len_of_term - pos_memory)\n",
    "                    break\n",
    "    if order_matching_string_rev == abbv_reversed:\n",
    "        return True, pos_memory_list[::-1]\n",
    "    else:\n",
    "        return False, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distribution_of_matching_characters(pos_of_chars_list, t):\n",
    "    term_intervals = []\n",
    "    len_of_term = len(t)\n",
    "    i = 0\n",
    "    while i < len_of_term:\n",
    "        sublist = []\n",
    "        j = i\n",
    "        while j < len_of_term and t[j] != \" \":\n",
    "            sublist.append(j)\n",
    "            j = j+ 1\n",
    "        i = j+1\n",
    "        term_intervals.append(sublist)\n",
    "        \n",
    "    splitted_term = t.split()      \n",
    "    \n",
    "    containment_list = []\n",
    "    for i, interval in enumerate(term_intervals):\n",
    "        contanment_sublist = []\n",
    "        for pos in pos_of_chars_list:\n",
    "            if (pos in interval) and (splitted_term[i][0] == t[pos]):\n",
    "                contanment_sublist.append(0)\n",
    "            elif pos in interval:\n",
    "                contanment_sublist.append(interval.index(pos))\n",
    "        if len(contanment_sublist) == 0:\n",
    "            contanment_sublist.append(-1)\n",
    "        containment_list.append(contanment_sublist)\n",
    "    \n",
    "    result_of_distribution_check = False\n",
    "    if len(containment_list) <= 1:\n",
    "        result_of_distribution_check = True\n",
    "    elif len (containment_list) >= 2:\n",
    "        non_zero_count = 0\n",
    "        for sublist in containment_list[1:]:\n",
    "            if len(sublist) == 1 and 0 not in sublist:\n",
    "                non_zero_count += 1\n",
    "        if non_zero_count == 0:\n",
    "            result_of_distribution_check = True\n",
    "    \n",
    "    return result_of_distribution_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illod(abbv, term, threshold=None):\n",
    "    if (abbv[0].lower() == term[0].lower()):\n",
    "        \n",
    "        \n",
    "        ###################################### Step (a) ##########################################\n",
    "        # check wether initial letters of tokens in t match with the letters in abbreviation\n",
    "        if check_initial_letters(abbv, term):\n",
    "            return True\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################################### Step (b) ########################################\n",
    "        # clean abbreviation and term from special characters and stopwords\n",
    "        a_, t_ = clean_string_pair_and_reduce_expansion(abbv, term)\n",
    "        if a_ == t_:\n",
    "            return True\n",
    "        \n",
    "        sanitized_abbv = clean_string(abbv) \n",
    "        sanitized_term = clean_string(term)\n",
    "        sanitized_term_without_stopswords = stop_words_handling(sanitized_term)\n",
    "        sanitized_term_without_stopswords_splitted  = sanitized_term_without_stopswords.split()\n",
    "        \n",
    "        ###################################### Step (c), (d), (e) ###############################\n",
    "        # Sequential call of the methods that check and compare lengths, order and distribution of characters\n",
    "        length_consistency = check_length_consistency(sanitized_abbv, sanitized_term_without_stopswords)\n",
    "        order, pos_of_chars_list = check_order(sanitized_abbv, sanitized_term_without_stopswords)\n",
    "        distribution = check_distribution_of_matching_characters(pos_of_chars_list, sanitized_term_without_stopswords)\n",
    "\n",
    "\n",
    "        if length_consistency and order and distribution:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        ################################## in case first letter differs ##########################\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the 3 different AEP-Detection Types (Section 4.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_count_false_negatives(algo, threshold):\n",
    "    FN = 0\n",
    "    for i, abb in enumerate(abbreviations):\n",
    "        if not algo(abb, expansions[i], threshold):\n",
    "            # print(\"\\\"\"+abb+\"\\\"\"+\", \"+\"\\\"\"+expansions[i]+\"\\\"\")\n",
    "            FN += 1\n",
    "    return FN, str(FN) + \" FALSE NEGATIVES. Pairs that could not be detected out of \" + str(len(abbreviations)) + \" given pairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_count_false_positives(algo, threshold, alpha):\n",
    "    test_set = set()\n",
    "    while len(test_set) <= alpha * len(abbreviations):\n",
    "        rd1 = random.randint(0, len(abbreviations)-1)\n",
    "        rd2 = random.randint(0, len(abbreviations)-1)\n",
    "        if abbreviations[rd1] != abbreviations[rd2]:\n",
    "            test_set.add ((abbreviations[rd1], expansions[rd2]))\n",
    "            \n",
    "    count_of_false_examples = 0\n",
    "    FP = 0\n",
    "    for j, tup in enumerate (test_set): \n",
    "        if algo(tup[0], tup[1], threshold):\n",
    "            count_of_false_examples += 1\n",
    "            FP +=1\n",
    "    return FP, str(FP) + \" FALSE POSITIVE detections out of \" +  str(len(test_set)) + \" created false examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_quality_parameters(alpha, algo, search_space_for_F1_optimization):\n",
    "    max_f1 = 0\n",
    "    best_values = []\n",
    "    for th_ in search_space_for_F1_optimization:\n",
    "        result_on_L = find_and_count_false_negatives(algo, th_)\n",
    "        result_on_S = find_and_count_false_positives(algo, th_, alpha)\n",
    "        FN = result_on_L[0]\n",
    "        FP = result_on_S[0]\n",
    "        TP = len(abbreviations) - FN\n",
    "        \n",
    "        # A classifier that does nothing is not useful. This serves to avoid a division by zero    \n",
    "        if FP + TP == 0:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = TP/(TP + FP)\n",
    "            recall = TP/(TP + FN)\n",
    "            f1 = (2*precision*recall)/(precision+recall)\n",
    "            \n",
    "        # memorise the best F1 value in the loop so far.       \n",
    "        if f1 > max_f1:\n",
    "            best_values = [th_, precision, recall, f1]\n",
    "            max_f1 = f1\n",
    "    return best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm (algorithm, F1_optimization_search_space):\n",
    "    eval_data = {}\n",
    "    for alpha in [8, 16, 24, 48, 72]: \n",
    "        eval_data[alpha] = determine_quality_parameters(alpha, algorithm, F1_optimization_search_space)\n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list = [h/100 for h in list(range(0,100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.214188</td>\n",
       "      <td>0.437850</td>\n",
       "      <td>0.287659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.128862</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.192839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.094178</td>\n",
       "      <td>0.331467</td>\n",
       "      <td>0.146680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.288354</td>\n",
       "      <td>0.088109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.253639</td>\n",
       "      <td>0.064010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        F1\n",
       "8        0.12   0.214188  0.437850  0.287659\n",
       "16       0.13   0.128862  0.382979  0.192839\n",
       "24       0.14   0.094178  0.331467  0.146680\n",
       "48       0.15   0.051999  0.288354  0.088109\n",
       "72       0.16   0.036627  0.253639  0.064010"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(evaluate_algorithm (fast_text_similarity, step_list), orient=\"index\", columns=[\"threshold\", \"precision\", \"recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.901629</td>\n",
       "      <td>0.805711</td>\n",
       "      <td>0.850976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.805711</td>\n",
       "      <td>0.812765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.755381</td>\n",
       "      <td>0.805711</td>\n",
       "      <td>0.779734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0.989109</td>\n",
       "      <td>0.559351</td>\n",
       "      <td>0.714592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983268</td>\n",
       "      <td>0.559351</td>\n",
       "      <td>0.713062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        F1\n",
       "8           1   0.901629  0.805711  0.850976\n",
       "16          1   0.819943  0.805711  0.812765\n",
       "24          1   0.755381  0.805711  0.779734\n",
       "48          0   0.989109  0.559351  0.714592\n",
       "72          0   0.983268  0.559351  0.713062"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LD (LEVENSHTEIN_DISTANCE)\n",
    "pd.DataFrame.from_dict(evaluate_algorithm (levensthein_distance_on_reduction_of_expansion, list(range(0, 4))), orient=\"index\", columns=[\"threshold\", \"precision\", \"recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.931533</td>\n",
       "      <td>0.830347</td>\n",
       "      <td>0.878034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.869795</td>\n",
       "      <td>0.830347</td>\n",
       "      <td>0.849613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.927645</td>\n",
       "      <td>0.760918</td>\n",
       "      <td>0.836050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.865054</td>\n",
       "      <td>0.760918</td>\n",
       "      <td>0.809651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.915726</td>\n",
       "      <td>0.681411</td>\n",
       "      <td>0.781380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        F1\n",
       "8        0.79   0.931533  0.830347  0.878034\n",
       "16       0.79   0.869795  0.830347  0.849613\n",
       "24       0.84   0.927645  0.760918  0.836050\n",
       "48       0.84   0.865054  0.760918  0.809651\n",
       "72       0.87   0.915726  0.681411  0.781380"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JWS (JARO-WINKLER-SIMILARITY)\n",
    "pd.DataFrame.from_dict(evaluate_algorithm (jaro_winkler_similarity_on_reduction_of_expansion, step_list), orient=\"index\", columns=[\"threshold\", \"precision\", \"recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.925802</td>\n",
       "      <td>0.775476</td>\n",
       "      <td>0.843998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.873067</td>\n",
       "      <td>0.758679</td>\n",
       "      <td>0.811863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.819722</td>\n",
       "      <td>0.758679</td>\n",
       "      <td>0.788020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.863805</td>\n",
       "      <td>0.653415</td>\n",
       "      <td>0.744023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.911092</td>\n",
       "      <td>0.602464</td>\n",
       "      <td>0.725312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        F1\n",
       "8        0.68   0.925802  0.775476  0.843998\n",
       "16       0.80   0.873067  0.758679  0.811863\n",
       "24       0.77   0.819722  0.758679  0.788020\n",
       "48       0.82   0.863805  0.653415  0.744023\n",
       "72       0.87   0.911092  0.602464  0.725312"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DC (DICE-COEFFICIENT)\n",
    "pd.DataFrame.from_dict(evaluate_algorithm (dice_coefficient_on_reduction_of_expansion , step_list), orient=\"index\", columns=[\"threshold\", \"precision\", \"recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.984290</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.946818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.978966</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.944348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.959929</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.935401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.923469</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.917746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.876749</td>\n",
       "      <td>0.912094</td>\n",
       "      <td>0.894072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        F1\n",
       "8          -1   0.984290  0.912094  0.946818\n",
       "16         -1   0.978966  0.912094  0.944348\n",
       "24         -1   0.959929  0.912094  0.935401\n",
       "48         -1   0.923469  0.912094  0.917746\n",
       "72         -1   0.876749  0.912094  0.894072"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ILLOD\n",
    "pd.DataFrame.from_dict(evaluate_algorithm (illod, [-1]), orient=\"index\", columns=[\"threshold\", \"precision\", \"recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
